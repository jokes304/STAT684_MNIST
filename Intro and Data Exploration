The Modified National Institute of Standards and Technology (MNIST) database is one that is commonly used as a demonstration of how well machine learning can solve the problem of image recognition. It's also used as a common baseline for new techniques. The original "NIST" dataset had the training dataset and the testing dataset coming from different sources (the former from Census Bureau employees, the latter from high school students). The "Modification" was to mix the two sources and recreate a new training and testing dataset. Other modifications were to fit each image in a 28x28 pixel box (784 total pixels per image), and anti-aliased, which essentially adds more subtle shades of gray to each image. 

There are 60000 images in training and 10000 in testing. We use the read_mnist() function as part of the dslabs package in order to download the training and test data from http://yann.lecun.com/exdb/mnist/. The data is downloaded as a list with two components--train and test. Each of these components is also a list of two components--images and labels. Images is a matrix with 784 columns, one for each pixel. The values in the matrix are between 0 and 255 and represent the shade of gray that that pixel is. Labels is a vector of digits 0 to 9, representing what the digit shown in the image is. 

We look at the summation of the columns as a brief data check--are any columns always 0 (e.g., always white) and therefore useless? We find that pixels 1-12, 17-32, 53-58, 83-86, 112-113, 141-142, 169, 477, 561, 645-646, 672-674, 700-702, 728-731, 755-760, and 781-784 are always 0. These largely represent the corners of the images. Several of the pixels around these ones are almost always white as well, and are likely not useful or inclined to produce overfitting if they are included in a model. 

A quick plot of the first two principal components shows that they only explain 16.8% of the total variation. They seem to separate the 0 labels from the rest of the values.
